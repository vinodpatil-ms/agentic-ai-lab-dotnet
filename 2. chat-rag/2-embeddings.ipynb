{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a8eea1",
   "metadata": {},
   "source": [
    "# üèãÔ∏è Fun with Text and Image Embeddings üçé\n",
    "\n",
    "Welcome to our **Health & Fitness** embeddings notebook! In this tutorial, we'll show you how to:\n",
    "1. **Initialize** an `AIProjectClient` to access your Azure AI Foundry project.\n",
    "2. **Embed text** using `OpenAIClient` with our fun health-themed phrases.\n",
    "3. **Embed images** using `OpenAIClient` (we're using Cohere's image embeddings model).\n",
    "4. **Generate a health-themed image** (example code) and display it.\n",
    "5. **Use a prompt template** for extra context.\n",
    "Let's get started and have some fun with our healthy ideas! üçè\n",
    "\n",
    "> **Disclaimer**: This notebook is for educational purposes only. Always consult a professional for medical advice.\n",
    "\n",
    "<img src=\"seq-diagrams/2-embeddings.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c1d34",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment\n",
    "\n",
    "#### Prerequisites:\n",
    "- Deploy a [text embeddings model](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/understand-embeddings) (**text-embedding-3-small**) in Azure AI Foundry\n",
    "- (Optional) Deploy a image embeddings model (**Cohere-embed-v3-english**) in Azure AI Foundry\n",
    "\n",
    "#\n",
    "\n",
    "We'll import our libraries and load the environment variables for:\n",
    "- `AI_FOUNDRY_PROJECT_ENDPOINT`: Your AI Foundry project endpoint.\n",
    "- `TEXT_EMBEDDING_MODEL`: The text embeddings model deployment name.\n",
    "- (Optional) `IMAGE_EMBEDDING_MODEL`: The image embeddings model deployment name.\n",
    "\n",
    "We'll import libraries, load environment variables, and create an `AIProjectClient`.\n",
    "\n",
    "> #### Complete [1-basic-chat-completion.ipynb](./1-basic-chat-completion.ipynb) notebook before starting this one\n",
    "\n",
    "\"Let's begin! üöÄ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5eabd3",
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Azure.Identity, 1.18.0-beta.2\"\n",
    "#r \"nuget: Azure.AI.Projects, 1.2.0-beta.5\"\n",
    "#r \"nuget: dotenv.net\"\n",
    "\n",
    "using System.IO;\n",
    "using System.ClientModel.Primitives;\n",
    "using Azure.Identity;\n",
    "using Azure.AI.Projects;\n",
    "using Azure.AI.Projects.OpenAI;\n",
    "using Azure.Core;\n",
    "using OpenAI;\n",
    "using OpenAI.Responses;\n",
    "using dotenv.net;\n",
    "using OpenAI.Embeddings;\n",
    "\n",
    "DotEnv.Load(new DotEnvOptions(envFilePaths: new[] { Path.Combine(\".\",\"..\", \".env\") })); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable OPENAI001\n",
    "\n",
    "var aiFoundryProjectEndpoint = new Uri(Environment.GetEnvironmentVariable(\"AI_FOUNDRY_PROJECT_ENDPOINT\"));\n",
    "var textEmbeddingModel = Environment.GetEnvironmentVariable(\"TEXT_EMBEDDING_MODEL\");\n",
    "var imageEmbeddingModel = Environment.GetEnvironmentVariable(\"IMAGE_EMBEDDING_MODEL\");\n",
    "var tenantId = Environment.GetEnvironmentVariable(\"TENANT_ID\");\n",
    "Console.WriteLine($\"üîë Using Tenant ID: {tenantId}\");\n",
    "\n",
    "OpenAIClient openAIClient;\n",
    "\n",
    "try\n",
    "{\n",
    "    var credential = new DefaultAzureCredential(new DefaultAzureCredentialOptions\n",
    "    {\n",
    "        TenantId = tenantId\n",
    "    });\n",
    "\n",
    "    var testToken = credential.GetToken(new TokenRequestContext(new[] { \"https://ai.azure.com/.default\" }));\n",
    "    Console.WriteLine(\"‚úÖ Successfully initialized Azure credentials with correct tenant!\");      \n",
    "\n",
    "    AIProjectClient projectClient = new(aiFoundryProjectEndpoint, credential);\n",
    "    Console.WriteLine(\"üéâ Successfully created AIProjectClient\");\n",
    "\n",
    "    var openAiEndpoint = $\"https://{projectClient.OpenAI.Endpoint.Authority.Replace(\".services.ai.\",\".openai.\")}/openai/v1\";\n",
    "    Console.WriteLine($\"Using OpenAI endpoint: {openAiEndpoint}\");\n",
    "    BearerTokenPolicy tokenPolicy = new(\n",
    "        credential,\n",
    "        \"https://ai.azure.com/.default\");\n",
    "\n",
    "    openAIClient = new(\n",
    "        authenticationPolicy: tokenPolicy,\n",
    "        options: new OpenAIClientOptions()\n",
    "        {\n",
    "            Endpoint = new(openAiEndpoint),\n",
    "        }\n",
    "    );\n",
    "    Console.WriteLine(\"üéâ Successfully created OpenAIClient.\");\n",
    "}\n",
    "catch (Exception ex)\n",
    "{\n",
    "    Console.WriteLine(\"‚ùå Error initializing client: \" + ex.Message);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a936a9",
   "metadata": {},
   "source": [
    "## 2. Text Embeddings\n",
    "\n",
    "We'll call `GetEmbeddingsClient()` from our `OpenAIClient` to retrieve the embeddings client. Then we'll embed some fun health-themed phrases:\n",
    "- üçé An apple a day keeps the doctor away\n",
    "- üèãÔ∏è 15-minute HIIT workout routine\n",
    "- üßò Mindful breathing exercises\n",
    "\n",
    "The output will be numeric vectors representing each phrase in semantic space. Let‚Äôs see those embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var textPhrases = new List<string>\n",
    "{\n",
    "    \"An apple a day keeps the doctor away üçé\",\n",
    "    \"15-minute HIIT workout routine üèãÔ∏è\",\n",
    "    \"Mindful breathing exercises üßò\"\n",
    "};\n",
    "EmbeddingClient embeddingClient = null;\n",
    "try\n",
    "{\n",
    "    embeddingClient = openAIClient.GetEmbeddingClient(textEmbeddingModel);\n",
    "    var response = await embeddingClient.GenerateEmbeddingsAsync(textPhrases);\n",
    "    foreach(var item in response.Value)\n",
    "    {\n",
    "        var vec = item.ToFloats().ToArray();\n",
    "        var sampleStr = $\"[{vec[0]},{vec[1]},...,{vec[vec.Length - 2]}, {vec[vec.Length - 1]}]\";\n",
    "        Console.WriteLine($\"Sentence {item.Index}: '{textPhrases[item.Index]}':\");\n",
    "        Console.WriteLine($\"Embedding length: {vec.Length}\");\n",
    "        Console.WriteLine($\"Sample: {sampleStr}\");\n",
    "    }\n",
    "}\n",
    "catch(Exception ex)\n",
    "{\n",
    "    Console.WriteLine(\"‚ùå Error generating text embeddings: \" + ex.Message);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e781e2",
   "metadata": {},
   "source": [
    "# 3. Prompt Template Example üìù\n",
    "\n",
    "Even though our focus is on embeddings, here's how you might prepend some context to a user message. Imagine you want to embed user text but first add a system prompt such as ‚ÄúYou are HealthFitGPT, a fitness guidance model‚Ä¶‚Äù This little extra helps set the stage for more context-aware embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var TEMPLATE_SYSTEM = @\"You are HealthFitGPT, a fitness guidance model.\n",
    "                        Please focus on healthy advice and disclaim you're not a doctor.\n",
    "                        User message:\"; //We'll append the user message after this.\n",
    "\n",
    "float[] EmbedWithTemplate(string userMessage)\n",
    "{\n",
    "    var fullPrompt = $\"{TEMPLATE_SYSTEM} {userMessage}\";\n",
    "    var embeddingResponse = embeddingClient.GenerateEmbeddingsAsync(new List<string> { fullPrompt }).Result;\n",
    "    return embeddingResponse.Value[0].ToFloats().ToArray();\n",
    "}\n",
    "\n",
    "var sampleUserText = \"Can you suggest a quick home workout for busy moms?\";\n",
    "var embeddingResult = EmbedWithTemplate(sampleUserText);\n",
    "Console.WriteLine(\"Embedding length: \" + embeddingResult.Length);\n",
    "Console.WriteLine(\"First few dims: \" + string.Join(\", \", embeddingResult.Take(8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b221c6",
   "metadata": {},
   "source": [
    "# 4. Image Embeddings\n",
    "\n",
    "Image embeddings typically require managed compute resources. While Azure AI Foundry offers specialized models (like **MedImageInsight**) for medical images, in this example we'll use Cohere's serverless image embedding model.\n",
    "\n",
    "Here we are using the **`hand-xray.png`** image to generate embeddings. This image (of a hand X-ray) is our fun nod to health-themed imagery!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "try{\n",
    "    // For image embeddings, we'll use a different approach since Cohere models\n",
    "    // are typically accessed through the inference client differently\n",
    "    Console.WriteLine(\"üîç Image embeddings require specific model deployment and may not be\");\n",
    "    Console.WriteLine(\"   available through the standard Azure OpenAI client.\");\n",
    "    Console.WriteLine(\"   This section demonstrates the concept but may need model-specific configuration.\");\n",
    "    \n",
    "    // Placeholder for when proper image embedding support is available\n",
    "    Console.WriteLine(\"‚ùå Image embedding functionality needs to be configured with the appropriate\");\n",
    "    Console.WriteLine(\"   Cohere image embedding model deployment and client setup.\");\n",
    "}   \n",
    "catch(Exception e){\n",
    "    Console.WriteLine(\"‚ùå Error embedding image:\", e);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc86f0f",
   "metadata": {},
   "source": [
    "# 5. Generate a Health-Related Image üèÉ (Optional)\n",
    "\n",
    ">   Note: The example below uses the OpenAI Client with Azure OpenAI's DALL-E 3 model.\n",
    "\n",
    "Let's generate a health-themed image using OpenAI's DALL-E-3 model. You'll need:\n",
    "\n",
    "1. A DALL-E-3 model deployment in your Microsoft Foundry resource\n",
    "2. OpenAIClient configured with your Microsoft Foundry OpenAI endpoint with DefaultAzureCredential authentication.\n",
    "\n",
    "We'll pass a simple prompt describing a healthy scenario and display the generated image inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable OPENAI001\n",
    "using Microsoft.DotNet.Interactive;\n",
    "using Microsoft.DotNet.Interactive.Formatting;\n",
    "using static Microsoft.DotNet.Interactive.Formatting.PocketViewTags;\n",
    "\n",
    "async Task<string> GenerateHealthImage(string prompt=\"A simple cartoon of a happy person jogging outdoors\")\n",
    "{\n",
    "    var imageClient = openAIClient.GetImageClient(\"dall-e-3\");\n",
    "    var imageGenOptions = new OpenAI.Images.ImageGenerationOptions\n",
    "    {\n",
    "        Style = OpenAI.Images.GeneratedImageStyle.Natural,\n",
    "        Quality = OpenAI.Images.GeneratedImageQuality.High,\n",
    "        Size = OpenAI.Images.GeneratedImageSize.W1024xH1792,\n",
    "        OutputFileFormat = OpenAI.Images.GeneratedImageFileFormat.Png,\n",
    "        ResponseFormat = OpenAI.Images.GeneratedImageFormat.Uri\n",
    "    };\n",
    "    var imageResponse = await imageClient.GenerateImageAsync(\n",
    "        prompt: \"A watercolor painting of fresh fruits and vegetables arranged in a heart shape\",\n",
    "        imageGenOptions\n",
    "    );\n",
    "    var imageUri = imageResponse.Value.ImageUri;\n",
    "    return imageUri.AbsoluteUri;\n",
    "}\n",
    "\n",
    "var imageUrl = await GenerateHealthImage(\"A watercolor painting of fresh fruits and vegetables arranged in a heart shape\");\n",
    "\n",
    "HTML($\"<img src=\\\"{imageUrl}\\\" alt=\\\"Health Image\\\" style=\\\"max-width:50%; height:50%;\\\" />\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46cae4",
   "metadata": {},
   "source": [
    "# 6. Wrap-Up & Next Steps\n",
    "\n",
    "üéâ We've shown how to:\n",
    "\n",
    "- Set up the AIProjectClient & OpenAIClient.\n",
    "- Get text embeddings using text-embedding-3-small.\n",
    "- Get image embeddings using Cohere-embed-v3-english on a health-themed (hand X-ray) image.\n",
    "- Generate a health-themed image (example code).\n",
    "- Use a prompt template to add system context to your embeddings.\n",
    "\n",
    "#### Where to go next?\n",
    "\n",
    "- Explore Evaluation for evaluating your embeddings.\n",
    "- Use Tracing using OpenTelemetry for end-to-end telemetry.\n",
    "- Build out a retrieval pipeline to compare similarity of embeddings.\n",
    "\n",
    "Have fun experimenting, and remember: when it comes to your health, always consult a professional!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
